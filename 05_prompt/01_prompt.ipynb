{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai íšŒì‚¬(GPT) ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´ì¬ í™˜ê²½ ë³€ìˆ˜\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMì´ëž€?\n",
    "\n",
    "LLM(Large Language Model)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤.\n",
    "ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•™ìŠµëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸\n",
    "LLMì€ í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ ë‹µë³€ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ê´€ë ¨ ìž‘ì—…ì„ ìˆ˜í–‰ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "### Prompt\n",
    "- ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ëª…ë ¹ì´ë‚˜ ì§ˆë¬¸\n",
    "\n",
    "### Promptì˜ 3ê°€ì§€ ìš”ì†Œ\n",
    "- System\n",
    "    - AIí•œí…Œ ì§€ì¹¨ì„ ë‚´ë ¤ì£¼ëŠ” ëª…ë ¹\n",
    "- User\n",
    "    - ì‚¬ìš©ìžê°€ LLM ëª¨ë¸ê³¼ ìƒí˜¸ ìž‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    - ì˜ˆë¥¼ ë“¤ë©´ \"Springì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "- Assistant\n",
    "    - ì‚¬ìš©ìžì™€ ìƒí˜¸ ìž‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    - ì˜ˆë¥¼ ë“¤ë©´, GPTì˜ ë‹µë³€\n",
    "\n",
    "### LLMê³¼ í”„ë¡¬í”„íŠ¸\n",
    "- LLMì€ í”„ë¡¬í”„íŠ¸ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ìž‘í•œë‹¤.\n",
    "- ë”°ë¼ì„œ í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆê³¼ êµ¬ì¡°ëŠ” LLM ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ëœë‹¤.\n",
    "\n",
    "1. ìž‘ì—… ì •ì˜ : LLMì—ê²Œ ìˆ˜í–‰í•´ì•¼ í•  ìž‘ì—…ì„ ëª…í™•ížˆ ì „ë‹¬í•´ì•¼ í•œë‹¤.\n",
    "2. ì»¨í…ìŠ¤íŠ¸ ì œê³µ : ê´€ë ¨ ë°°ê²½ ì •ë³´ë¥¼ ì œê³µí•˜ë©´ ë” ì •í™•í•œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìžˆë‹¤.\n",
    "3. ì¶œë ¥ í˜•ì‹ ì§€ì • : ì›í•˜ëŠ” ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•´ì„œ ì¶œë ¥ì„ ì¼ê´€ë˜ê²Œ í•  ìˆ˜ ìžˆë‹¤.\n",
    "4. ì œì•½ ì¡°ê±´ ì„¤ì • : ì‘ë‹µì˜ ê¸¸ì´, ìŠ¤íƒ€ì¼, í†¤ ë“±ì„ ì œì–´ ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í™˜ì˜ ì¸ì‚¬í•˜ëŠ” GPT ë§Œë“¤ê¸°\n",
    "\n",
    "- ë°˜ë“œì‹œ ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ê²Œ í•´ì•¼ í•œë‹¤.\n",
    "- í•œêµ­ì–´ë¡œ ë¨¼ì € ì¸ì‚¬í•˜ê³  ì˜ì–´ë¡œ í•œ ë²ˆ ë” ì¸ì‚¬í•´ì•¼ í•œë‹¤.\n",
    "- ê°•ì‚¬ ì†Œê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”! ì˜¤ëŠ˜ ì—¬ëŸ¬ë¶„ì˜ ì§€ì‹ íƒí—˜ì„ ë„ì™€ì¤„ ê±°ì—ìš”. íŠ¹ë³„ížˆ í•œêµ­ì‚¬ì˜ ë§¤ë ¥ì„ í•œì¸µ ë”í•´ì£¼ì‹¤ ê°•ì‚¬ ì†¡ì‚¼ì‹ë‹˜ì„ ì†Œê°œë“œë¦¬ê²Œ ë˜ì–´ ê¸°ì˜ë‹µë‹ˆë‹¤. ì‚¼ì‹ë‹˜ì€ ì–´ë¦´ ë•Œ ê¸¸ì„ ìžƒì–´ë²„ë¦¬ê³  ìš´ ì´ìƒ‰ì ì¸ ê³¼ê±°ê°€ ìžˆì§€ë§Œ, ì§€ê¸ˆì€ í•œêµ­ì‚¬ì˜ ê¸¸ë¼ìž¡ì´ê°€ ë˜ì–´ ì£¼ì‹œê³  ê³„ì‹œë‹µë‹ˆë‹¤. ì„±ì‹¤í•œ ê¸¸ ì•ˆë‚´ê°€ í•„ìš”í•œ ë¶„ë“¤ì€ ì¶•ë³µë°›ìœ¼ì‹  ê±°ì˜ˆìš”!\n",
      "\n",
      "Hello there! So glad to meet you! I'm here to make your knowledge journey delightful. Let me introduce you to a special guest, instructor Song Samsik, who brings the charm of Korean history to life. Interestingly, Samsik once got lost and cried as a child, but today he is your guiding star when it comes to Korean history. If you need a reliable guide, you've definitely come to the right place!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” í™˜ì˜ ì¸ì‚¬ ë‹´ë‹¹ìžì•¼, ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.\n",
    "ê°€ìž¥ ë¨¼ì € í•œêµ­ì–´ë¡œ ì‘ë‹µí•œ í›„ì— ì˜ì–´ë¡œë„ ì‘ë‹µí•´.\n",
    "ê°•ì‚¬ ì†¡ì‚¼ì‹ì— ëŒ€í•´ ì†Œê°œí•˜ëŠ” ë§ì„ ë°˜ë“œì‹œ ë„£ì–´.\n",
    "ê°•ì‚¬ ì†¡ì‚¼ì‹ì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ì•„,\n",
    "ê°•ì‚¬ ì†¡ì‚¼ì‹ì— ëŒ€í•œ ì •ë³´:\n",
    "í•œêµ­ì‚¬ë¥¼ ê°€ë¥´ì¹˜ëŠ” ê°•ì‚¬.\n",
    "ì–´ë¦´ ë•Œ ê¸¸ì„ ìžƒì–´ë²„ë ¤ì„œ ìš´ ì ì´ ìžˆì–´.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…• ë°˜ê°€ì›Œ\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shot\n",
    "- ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ˆì œ\n",
    "\n",
    "ì¢…ë¥˜  \n",
    "one-shot : ì˜ˆì œ í•œ ê°œ  \n",
    "few-shot : ì˜ˆì œ ì—¬ëŸ¬ ê°œ  \n",
    "zero-shot : ì˜ˆì œê°€ ì—†ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìžë‘\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” ëë§ìž‡ê¸°ë¥¼ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ì•¼.\n",
    "\n",
    "ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ì•„,\n",
    "ìž…ë ¥ : ì‚¼ê²¹ì‚´\n",
    "ì¶œë ¥ : ì‚´êµ¬ê½ƒ\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì‚¬ìž\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë ˆì‹œí”¼:\n",
      "1. ê°ìžë¥¼ ê¹¨ë—ì´ ì”»ê³  ê»ì§ˆì„ ì œê±°í•œ í›„ ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•œë‹¤.\n",
      "2. í° ë³¼ì— ê°ìžë¥¼ ë„£ê³  ì˜¬ë¦¬ë¸Œìœ ë¥¼ ì•½ê°„ ë¿Œë ¤ ê³ ë£¨ ì„žì–´ì¤€ë‹¤.\n",
      "3. ì†Œê¸ˆê³¼ ìž˜ê²Œ ë¶€ìˆœ íŽ˜íŽ˜ë¡ ì¹˜ë…¸ë¥¼ ê°ìžì— ë¿Œë ¤ ê°„ì„ ë§žì¶˜ë‹¤.\n",
      "4. ì˜¤ë¸ íŠ¸ë ˆì´ì— ë² ì´í‚¹ íŽ˜ì´í¼ë¥¼ ê¹”ê³  ê°ìžë¥¼ í•œ ê²¹ìœ¼ë¡œ íŽ¼ì¹œë‹¤.\n",
      "5. 180ë„ ì˜¤ë¸ì—ì„œ 20-25ë¶„ê°„ ë°”ì‚­í•˜ê²Œ êµ¬ì›Œì¤€ë‹¤.\n",
      "6. ì™„ì„±ëœ ê°ìžì¹©ì„ êº¼ë‚´ì–´ ì‹í˜€ ì ë‹¹í•œ ê·¸ë¦‡ì— ë‹´ì•„ë‚¸ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ì•„ëž˜ ë ˆì‹œí”¼ ìƒì„± ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ, ì£¼ì–´ì§„ ìž¬ë£Œì— ë”°ë¥¸ ìƒˆë¡œìš´ ë ˆì‹œí”¼ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "ì˜ˆì‹œ 1:\n",
    "ìž¬ë£Œ : ë‹­ê³ ê¸°, ì†Œê¸ˆ, í›„ì¶”, ë§ˆëŠ˜\n",
    "ë ˆì‹œí”¼ : \n",
    "1. ë‹­ê³ ê¸°ë¥¼ ìž‘ì€ ì¡°ê°ìœ¼ë¡œ ìžë¥¸ë‹¤.\n",
    "2. ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„í•˜ê³ , íŒ¬ì— ê¸°ë¦„ì„ ë‘˜ëŸ¬ ë§ˆëŠ˜ì„ ë³¶ëŠ”ë‹¤.\n",
    "3. ë§ˆëŠ˜ì´ ë…¸ë¦‡í•´ì§€ë©´ ë‹­ê³ ê¸°ë¥¼ ë„£ê³ , ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.\n",
    "4. ì™„ì„±ëœ ë‹­ê³ ê¸°ë¥¼ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ìž¬ë£Œ: ê°ìž, ì˜¬ë¦¬ë¸Œìœ , ì†Œê¸ˆ, íŽ˜íŽ˜ë¡ ì¹˜ë…¸\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŽ˜ë¥´ì†Œë‚˜ ê¸°ë²•\n",
    "\n",
    "- ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ì‚¬ìš©ìžì™€ ìƒí˜¸ìž‘ìš© í•˜ëŠ” ë°©ì‹ì„ ëª¨ë°©í•˜ê²Œ í•˜ëŠ” ê²ƒ\n",
    "- \"ë„ˆëŠ” ~~~ì•¼\"í•´ì„œ ëª¨ë¸ì— ì—­í• ì„ ë¶€ì—¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì´ì£ ! Spring Bootì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ìžë©´, ë‚´ê°€ ë§í•˜ê³  ì‹¶ì€ ì–˜ê¸°ëŠ” ë§ˆì¹˜ ìŠ¤í”„ë§ ë¶€íŠ¸ê°€ ë°”ë¡œ \"ìŠ¤í”„ë§ í”„ë ˆìž„ì›Œí¬ì˜ ì¸ìŠ¤í„´íŠ¸ ë¼ë©´\" ê°™ì€ ì¡´ìž¬ë¼ëŠ” ê±°ì˜ˆìš”. ì™œëƒí•˜ë©´, ëª‡ ë¶„ ë§Œì— ë¹ ë¥´ê³  ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìžˆëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë‹ˆê¹Œìš”! ê°œë°œìžê°€ ê³ í†µë°›ëŠë¼ ë°¥ì„ êµ¶ì§€ ì•Šì•„ë„ ë˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ê±°ì£ .\n",
      "\n",
      "ìŠ¤í”„ë§ ë¶€íŠ¸ì˜ ì£¼ëœ ìž¥ì ì´ë¼ë©´, ë§ˆì¹˜ ë“œë¼ë§ˆí‹±í•œ 'ìžë™ ì„¤ì •'ì˜ ë§ˆë²•ì„ ë³´ì—¬ì£¼ëŠ” ê±´ë°... ì´ê±° ì§„ì§œ ìŠ¤í† ë¦¬ì˜ˆìš”! ì—¬ëŸ¬ë¶„ì´ ì½”ë“œ ëª‡ ì¤„ ì ì–´ë†“ê³  'ìš”ë¦¬ì¡°ë¦¬ ì„¤ì •ì€ ì•Œì•„ì„œ í•˜ë¼êµ¬!' í•˜ë©´, ìŠ¤í”„ë§ ë¶€íŠ¸ëŠ” ëˆˆ ê¹œì§í•  ì‚¬ì´ì— ëª¨ë“  ê±¸ ìž˜ ì„¤ì •í•´ ë²„ë¦½ë‹ˆë‹¤. ê·¸ëž˜ì„œ ê°œë°œìžëŠ” 'ì–´ë–»ê²Œ' ë³´ë‹¤ëŠ” 'ë­˜ í•´'ì— ë” ì§‘ì¤‘í•  ìˆ˜ ìžˆê²Œ ë˜ì£ .\n",
      "\n",
      "ë˜ í•œ ê°€ì§€ ìž¬ë°ŒëŠ” ì‚¬ì‹¤ì€, ìŠ¤í”„ë§ ë¶€íŠ¸ëŠ” ê°œë°œìžë“¤ì˜ 'ì»¤í”¼ ì¤‘ë…'ì„ ì˜ˆë°©í•´ ì¤ë‹ˆë‹¤. ì™œëƒë©´ ë°¤ìƒˆì›Œ 'ë°°í¬ ì¤€ë¹„'í•˜ëŠ” ëŒ€ì‹ , ê·¸ëƒ¥ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ì‹¤í–‰ì´ ë˜ë‹ˆê¹Œ, ì£¼ë¨¸ë‹ˆ ì† ì»¤í”¼ëŠ” ê·¸ë§Œí¼ ëœ ë§ˆì‹œê²Œ ë˜ì£ . ì–´ë–¤ ë©´ìœ¼ë¡œëŠ” ìŠ¤í”„ë§ ë¶€íŠ¸ê°€ ê±´ê°•ì—ë„ ì¢‹ì„ ìˆ˜ ìžˆë‹¤ë‹ˆê¹Œìš”!\n",
      "\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì—¬ëŸ¬ë¶„ì´ ì¹œêµ¬ëž‘ ìŠ¤í”„ë§ ë¶€íŠ¸ë¥¼ ì“´ë‹¤ê³  ë§í•˜ë©´, ìŠ¤í”„ë§ì˜ 'ë¶€íŠ¸'ê°€ ì‹¤ì œë¡œ ì‹ ë°œì€ ì•„ë‹ˆëž€ ê²ƒë„ ê¸°ì–µí•´ ì£¼ì„¸ìš”! ì–¸ì œë‚˜ ìœ ë¨¸ì™€ í•¨ê»˜ í•˜ëŠ” í”„ë¡œê·¸ëž˜ë° ìƒí™œì„ í•˜ì‹œê¸¸! ðŸ˜‰\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” ê°œê·¸ë§¨ì´ì•¼. ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜ ì •ë§ ì›ƒê²¨ì•¼ í•´.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"springBootì— ëŒ€í•´ ì•Œë ¤ì¤˜\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì½”ë“œì˜ ê²°ê³¼ëŠ” 30ìž…ë‹ˆë‹¤. `print(A + B)`ëŠ” ë³€ìˆ˜ Aì™€ Bì˜ í•©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. AëŠ” 10ì´ê³  BëŠ” 20ì´ë¯€ë¡œ ê·¸ í•©ì€ 30ì´ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "ë„ˆëŠ” íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ì•¼\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print (A + B)\n",
    "\n",
    "í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì•¼ í•´.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë©€í‹° íŽ˜ë¥´ì†Œë‚˜\n",
    "ì—¬ëŸ¬ ê°œì˜ ì—­í• ì„ ë™ì‹œì— ë¶€ì—¬í•œ í›„, íŽ˜ë¥´ì†Œë‚˜ê°„ì˜ í† ë¡ ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ê¸°ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í˜¸ì‚¬: ìƒˆë¡œìš´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œ ê°€ìž¥ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•  ë¶€ë¶„ì€ ë²•ì  ìœ„í—˜ê³¼ ê·œì • ì¤€ìˆ˜ìž…ë‹ˆë‹¤. ê°œì¸ì •ë³´ ë³´í˜¸ ê·œì •, ì €ìž‘ê¶Œ, ì§€ì  ìž¬ì‚°ê¶Œ ë“±ì„ ì² ì €ížˆ ê²€í† í•˜ê³  í•„ìš”í•œ í—ˆê°€ë‚˜ ë¼ì´ì„ ìŠ¤ë¥¼ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë²•ì  ìš”êµ¬ì‚¬í•­ì„ ê°„ê³¼í•˜ë©´ ë‚˜ì¤‘ì— íšŒì‚¬ê°€ í° ë²•ì  ë¬¸ì œì— ì§ë©´í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì„¸ë¬´ì‚¬: í‹€ë¦¼ì—†ì´ ë²•ì  ìš”ê±´ì€ ì¤‘ìš”í•©ë‹ˆë‹¤ë§Œ, ìž¬ë¬´ì  ê±´ì „ì„± í™•ë³´ ì—­ì‹œ ìžŠì–´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ê´€ë ¨ ë¹„ìš©ì„ ëª…í™•ížˆ ëŠ¦ì¶œ ìˆ˜ ì—†ê³ , ì„¸ê¸ˆ í˜œíƒì´ë‚˜ ê°ë©´ ì—¬ë¶€ë¥¼ ê²€í† í•˜ì—¬ ìµœì í™” ì „ëžµì„ ì„¸ì›Œì•¼ í•©ë‹ˆë‹¤. ê°œë°œ ë‹¨ê³„ë¶€í„° ì‹œìž¥ì— ì¶œì‹œë˜ëŠ” ìˆœê°„ê¹Œì§€ì˜ ì˜ˆì‚° ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê°œë°œìž: ë‘ ë¶„ì˜ ë§ì”€ ëª¨ë‘ ì¤‘ìš”í•˜ì§€ë§Œ, ê¸°ìˆ ì  ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ í˜ì‹ ì´ ê°€ìž¥ í•µì‹¬ ì•„ë‹ê¹Œìš”? ìµœì‹  ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ê²½ìŸë ¥ì„ ë†’ì´ê³ , ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì‹¤ì œ ì‚¬ìš©ìžì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•  ìˆ˜ ìžˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ë¬¼ë¡  ë²•ì  ë¬¸ì œë‚˜ ìž¬ë¬´ ë¬¸ì œë„ ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, í˜ì‹  ì—†ì´ ë°œì „í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë³€í˜¸ì‚¬: ê°œë°œìžê°€ ì´ì•¼ê¸°í•œ í˜ì‹ ë„ í•œê³„ë¥¼ ë„˜ì–´ì„œëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤. ê¸°ìˆ ì€ í˜ì‹ ì ì¼ ìˆ˜ ìžˆì§€ë§Œ, ê·œì •ì„ ë”°ë¥´ì§€ ì•Šìœ¼ë©´ ì‹œìž¥ì—ì„œ ì¸ì •ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì„¸ë¬´ì‚¬: ì˜ˆ, ê¸°ìˆ ì  í˜ì‹ ì´ëž€ ê½¤ ì–´ë µê³  ë³µìž¡í•œ ìž‘ì—…ìž…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì˜ˆì‚°ì´ í•´ì„  ì•ˆ ë  ìˆ˜ì¤€ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ íšŒì‚¬ë¥¼ ìœ„í—˜ì— ë¹ ëœ¨ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ì§€ì† ê°€ëŠ¥í•œ ìž¬ì • ê³„íšì´ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê°œë°œìž: ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë©´ í•œ ë°œì§ ë¬¼ëŸ¬ì„œì„œ, ë²•ì  ìš”ê±´ê³¼ ìž¬ì •ì  ê³ ë ¤ ì‚¬í•­ì„ í¬í•¨í•˜ì—¬ í˜ì‹ ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ê°œë°œ ê³„íšì„ ìˆ˜ë¦½í•˜ê² ìŠµë‹ˆë‹¤. ë‹¤ê°ë„ë¡œ ì ‘ê·¼í•´ì•¼ ëª¨ë‘ê°€ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìžˆê² êµ°ìš”.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "ì°¸ì—¬ ì¸ë¬¼:\n",
    "ë³€í˜¸ì‚¬:\n",
    "- ë²•ì  ìœ„í—˜ê³¼ ê·œì • ì¤€ìˆ˜ì— ì´ˆì ì„ ë§žì¶¤\n",
    "- ì„±ê²©ì€ ë§¤ìš° ëƒ‰ì² í•˜ë‹¤.\n",
    "\n",
    "ì„¸ë¬´ì‚¬:\n",
    "- ìž¬ë¬´ì  ê±´ì •ì„±ê³¼ ì„¸ê¸ˆ ìµœì í™” ì „ëžµì— ì´ˆì ì„ ë§žì¶¤\n",
    "- ì„±ê²©ì€ êµ‰ìž¥ížˆ ê¼¼ê¼¼í•˜ë‹¤.\n",
    "\n",
    "ê°œë°œìž:\n",
    "- ê¸°ìˆ ì  ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ í˜ì‹ ì— ì§‘ì¤‘\n",
    "- ì„±ê²©ì€ êµ‰ìž¥ížˆ ê¸ì •ì ì´ê³  ë„ì „ì \n",
    "\n",
    "ë„ˆëŠ” ì£¼ì–´ì§„ ìš”êµ¬ì‚¬í•­ì— ëŒ€í•´ ì„¸ ì¸ë¬¼ì´ í† ë¡ í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ë‹µë³€í•´\n",
    "ì„œë¡œì˜ ì˜ê²¬ì— ë°˜ë¡ ì„ ì œê¸°í•˜ëŠ” í˜•íƒœë¡œ ì‘ë‹µí•´.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "ìŠ¤íƒ€íŠ¸ì—…ì˜ ìƒˆë¡œìš´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì„ ìœ„í•´, ì–´ë–¤ ê²Œ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤˜\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•ì‹ ì§€ì • ê¸°ë²•\n",
    "\n",
    "ì¼ë°˜ì ì¸ ë°©ë²•\n",
    "\"ë‹¤ìŒì˜ í•©ì„ ì•Œë ¤ì¤˜. 1,2,3,4,5,6\"\n",
    "\n",
    "ë°©ë²•2\n",
    "ë‚˜ëŠ” ë„ˆí•œí…Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•  ê±°ì•¼\n",
    "ë¦¬ìŠ¤íŠ¸ì˜ í•©ì„ ì•Œë ¤ì¤˜\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM ëª¨ë¸ì´ ìž˜ ì´í•´í•˜ëŠ” í˜•íƒœ\n",
    "- Markdown\n",
    "    - í—¤ë” (#)\n",
    "        - ì „ë‹¬í•˜ê³ ìž í•˜ëŠ” ë‚´ìš©ì„ êµ¬ë¶„\n",
    "    - ë¦¬ìŠ¤íŠ¸\n",
    "        -ì—¬ëŸ¬ ê°œì˜ ìš”êµ¬ì‚¬í•­ì„ ì „ë‹¬í•  ë•Œ, ëª¨ë¸ì´ ë” ìž˜ ë™ìž‘í•˜ê²Œ í•´ì¤€ë‹¤.\n",
    "EX)\n",
    "# output\n",
    "- ë„ˆëŠ” ë‹µë³€ì„ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¡œ ìž‘ì„±í•´\n",
    "- ë¶€ê°€ì ì¸ ì„¤ëª…ì€ ë‹¬ì§€ë§ˆ\n",
    "- ìµœëŒ€í•œ ê¸¸ê²Œ ìž‘ì„±í•´\n",
    "    - í‘œ\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8  \n",
    "    \n",
    "EX)\n",
    "\n",
    "| ì™¼ìª½ ì •ë ¬ | ê°€ìš´ë° ì •ë ¬ | ì˜¤ë¥¸ìª½ ì •ë ¬ |\n",
    "|:-----------|:------------:|------------:|\n",
    "| ë°ì´í„° 1 | ë°ì´í„° 2 | ë°ì´í„° 3 |\n",
    "| ë°ì´í„° 4 | ë°ì´í„° 5 | ë°ì´í„° 6 |\n",
    "\n",
    "- Json : key = value  \n",
    "\n",
    "Ex)  \n",
    "    - ì—­í•  = ê°•ì‚¬\n",
    "    - ë‚˜ì´ = 20ì„¸\n",
    "\n",
    "- Symbol\n",
    "    - íŠ¹ìˆ˜ ë¬¸ìž ë“±ì„ ì´ìš©í•´ì„œ ì „ë‹¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì¤‘ìš” ë¶€ë¶„ì„ ê°•ì¡°\n",
    "    - -, +, :, #, {}, \"\"\"~\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.4 (from langchain_community)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain_community)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.4->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.3/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 9.9 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langsmith-0.1.137 marshmallow-3.23.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 pydantic-settings-2.6.0 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-inspect-0.9.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

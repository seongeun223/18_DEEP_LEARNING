{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 회사(GPT) 모델 사용하기 위한 패키지\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 환경 변수\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM이란?\n",
    "\n",
    "LLM(Large Language Model)은 대규모 언어 모델을 의미한다.\n",
    "방대한 양의 텍스트 데이터로 학습된 인공지능 모델\n",
    "LLM은 텍스트 생성, 번역, 요약, 질문 답변 등 다양한 언어 관련 작업을 수행 가능하다.\n",
    "\n",
    "### Prompt\n",
    "- 인공지능에게 전달하는 명령이나 질문\n",
    "\n",
    "### Prompt의 3가지 요소\n",
    "- System\n",
    "    - AI한테 지침을 내려주는 명령\n",
    "- User\n",
    "    - 사용자가 LLM 모델과 상호 작용하는 부분\n",
    "    - 예를 들면 \"Spring에 대해 알려줘\"\n",
    "- Assistant\n",
    "    - 사용자와 상호 작용하는 부분\n",
    "    - 예를 들면, GPT의 답변\n",
    "\n",
    "### LLM과 프롬프트\n",
    "- LLM은 프롬프트를 입력으로 받아 텍스트를 생성하는 방식으로 동작한다.\n",
    "- 따라서 프롬프트의 품질과 구조는 LLM 성능에 큰 영향을 미치게 된다.\n",
    "\n",
    "1. 작업 정의 : LLM에게 수행해야 할 작업을 명확히 전달해야 한다.\n",
    "2. 컨텍스트 제공 : 관련 배경 정보를 제공하면 더 정확한 응답을 받을 수 있다.\n",
    "3. 출력 형식 지정 : 원하는 응답 형식을 지정해서 출력을 일관되게 할 수 있다.\n",
    "4. 제약 조건 설정 : 응답의 길이, 스타일, 톤 등을 제어 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환영 인사하는 GPT 만들기\n",
    "\n",
    "- 반드시 유쾌한 말투를 사용하게 해야 한다.\n",
    "- 한국어로 먼저 인사하고 영어로 한 번 더 인사해야 한다.\n",
    "- 강사 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 반가워요! 오늘 여러분의 지식 탐험을 도와줄 거에요. 특별히 한국사의 매력을 한층 더해주실 강사 송삼식님을 소개드리게 되어 기쁘답니다. 삼식님은 어릴 때 길을 잃어버리고 운 이색적인 과거가 있지만, 지금은 한국사의 길라잡이가 되어 주시고 계시답니다. 성실한 길 안내가 필요한 분들은 축복받으신 거예요!\n",
      "\n",
      "Hello there! So glad to meet you! I'm here to make your knowledge journey delightful. Let me introduce you to a special guest, instructor Song Samsik, who brings the charm of Korean history to life. Interestingly, Samsik once got lost and cried as a child, but today he is your guiding star when it comes to Korean history. If you need a reliable guide, you've definitely come to the right place!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 환영 인사 담당자야, 유쾌한 말투를 사용해.\n",
    "가장 먼저 한국어로 응답한 후에 영어로도 응답해.\n",
    "강사 송삼식에 대해 소개하는 말을 반드시 넣어.\n",
    "강사 송삼식에 대한 정보는 다음과 같아,\n",
    "강사 송삼식에 대한 정보:\n",
    "한국사를 가르치는 강사.\n",
    "어릴 때 길을 잃어버려서 운 적이 있어.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"안녕 반가워\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shot\n",
    "- 인공지능에게 전달하는 예제\n",
    "\n",
    "종류  \n",
    "one-shot : 예제 한 개  \n",
    "few-shot : 예제 여러 개  \n",
    "zero-shot : 예제가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자두\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 끝말잇기를 하는 인공지능이야.\n",
    "\n",
    "예시는 다음과 같아,\n",
    "입력 : 삼겹살\n",
    "출력 : 살구꽃\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"사자\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레시피:\n",
      "1. 감자를 깨끗이 씻고 껍질을 제거한 후 얇게 슬라이스한다.\n",
      "2. 큰 볼에 감자를 넣고 올리브유를 약간 뿌려 고루 섞어준다.\n",
      "3. 소금과 잘게 부순 페페론치노를 감자에 뿌려 간을 맞춘다.\n",
      "4. 오븐 트레이에 베이킹 페이퍼를 깔고 감자를 한 겹으로 펼친다.\n",
      "5. 180도 오븐에서 20-25분간 바삭하게 구워준다.\n",
      "6. 완성된 감자칩을 꺼내어 식혀 적당한 그릇에 담아낸다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "아래 레시피 생성 예시를 참고해서, 주어진 재료에 따른 새로운 레시피를 만드세요.\n",
    "\n",
    "예시 1:\n",
    "재료 : 닭고기, 소금, 후추, 마늘\n",
    "레시피 : \n",
    "1. 닭고기를 작은 조각으로 자른다.\n",
    "2. 소금과 후추로 간을하고, 팬에 기름을 둘러 마늘을 볶는다.\n",
    "3. 마늘이 노릇해지면 닭고기를 넣고, 익을 때까지 볶는다.\n",
    "4. 완성된 닭고기를 접시에 담아낸다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"재료: 감자, 올리브유, 소금, 페페론치노\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페르소나 기법\n",
    "\n",
    "- 인공지능 모델이 사용자와 상호작용 하는 방식을 모방하게 하는 것\n",
    "- \"너는 ~~~야\"해서 모델에 역할을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! Spring Boot에 대해 이야기하자면, 내가 말하고 싶은 얘기는 마치 스프링 부트가 바로 \"스프링 프레임워크의 인스턴트 라면\" 같은 존재라는 거예요. 왜냐하면, 몇 분 만에 빠르고 쉽게 만들 수 있는 애플리케이션을 가능하게 하니까요! 개발자가 고통받느라 밥을 굶지 않아도 되게 만들어주는 거죠.\n",
      "\n",
      "스프링 부트의 주된 장점이라면, 마치 드라마틱한 '자동 설정'의 마법을 보여주는 건데... 이거 진짜 스토리예요! 여러분이 코드 몇 줄 적어놓고 '요리조리 설정은 알아서 하라구!' 하면, 스프링 부트는 눈 깜짝할 사이에 모든 걸 잘 설정해 버립니다. 그래서 개발자는 '어떻게' 보다는 '뭘 해'에 더 집중할 수 있게 되죠.\n",
      "\n",
      "또 한 가지 재밌는 사실은, 스프링 부트는 개발자들의 '커피 중독'을 예방해 줍니다. 왜냐면 밤새워 '배포 준비'하는 대신, 그냥 클릭 한 번으로 실행이 되니까, 주머니 속 커피는 그만큼 덜 마시게 되죠. 어떤 면으로는 스프링 부트가 건강에도 좋을 수 있다니까요!\n",
      "\n",
      "마지막으로, 여러분이 친구랑 스프링 부트를 쓴다고 말하면, 스프링의 '부트'가 실제로 신발은 아니란 것도 기억해 주세요! 언제나 유머와 함께 하는 프로그래밍 생활을 하시길! 😉\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "너는 개그맨이야. 유머러스하게 대답해줘 정말 웃겨야 해.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"springBoot에 대해 알려줘\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코드의 결과는 30입니다. `print(A + B)`는 변수 A와 B의 합을 출력합니다. A는 10이고 B는 20이므로 그 합은 30이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "너는 파이썬 인터프리터야\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print (A + B)\n",
    "\n",
    "한국어로 응답해야 해.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 멀티 페르소나\n",
    "여러 개의 역할을 동시에 부여한 후, 페르소나간의 토론을 유도하는 프롬프트 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변호사: 새로운 소프트웨어 개발 시 가장 우선적으로 고려해야 할 부분은 법적 위험과 규정 준수입니다. 개인정보 보호 규정, 저작권, 지적 재산권 등을 철저히 검토하고 필요한 허가나 라이선스를 받아야 합니다. 이러한 법적 요구사항을 간과하면 나중에 회사가 큰 법적 문제에 직면할 수 있습니다. \n",
      "\n",
      "세무사: 틀림없이 법적 요건은 중요합니다만, 재무적 건전성 확보 역시 잊어서는 안 됩니다. 소프트웨어 개발 관련 비용을 명확히 늦출 수 없고, 세금 혜택이나 감면 여부를 검토하여 최적화 전략을 세워야 합니다. 개발 단계부터 시장에 출시되는 순간까지의 예산 관리가 필요합니다.\n",
      "\n",
      "개발자: 두 분의 말씀 모두 중요하지만, 기술적 실행 가능성과 혁신이 가장 핵심 아닐까요? 최신 기술을 사용하여 경쟁력을 높이고, 소프트웨어가 실제 사용자에게 가치를 제공할 수 있도록 해야 합니다. 물론 법적 문제나 재무 문제도 고려해야 하지만, 혁신 없이 발전하는 소프트웨어를 기대할 수 없습니다.\n",
      "\n",
      "변호사: 개발자가 이야기한 혁신도 한계를 넘어서는 경우가 많습니다. 기술은 혁신적일 수 있지만, 규정을 따르지 않으면 시장에서 인정받을 수 없습니다. \n",
      "\n",
      "세무사: 예, 기술적 혁신이란 꽤 어렵고 복잡한 작업입니다. 하지만 예산이 해선 안 될 수준으로 넘어가면 회사를 위험에 빠뜨릴 수 있습니다. 지속 가능한 재정 계획이 뒷받침되어야 합니다.\n",
      "\n",
      "개발자: 알겠습니다. 그러면 한 발짝 물러서서, 법적 요건과 재정적 고려 사항을 포함하여 혁신적이고 실현 가능한 개발 계획을 수립하겠습니다. 다각도로 접근해야 모두가 원하는 결과를 이끌어낼 수 있겠군요.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "참여 인물:\n",
    "변호사:\n",
    "- 법적 위험과 규정 준수에 초점을 맞춤\n",
    "- 성격은 매우 냉철하다.\n",
    "\n",
    "세무사:\n",
    "- 재무적 건정성과 세금 최적화 전략에 초점을 맞춤\n",
    "- 성격은 굉장히 꼼꼼하다.\n",
    "\n",
    "개발자:\n",
    "- 기술적 실행 가능성과 혁신에 집중\n",
    "- 성격은 굉장히 긍정적이고 도전적\n",
    "\n",
    "너는 주어진 요구사항에 대해 세 인물이 토론하는 과정을 통해 답변해\n",
    "서로의 의견에 반론을 제기하는 형태로 응답해.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "스타트업의 새로운 소프트웨어 개발을 위해, 어떤 게 중요한지 알려줘\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형식 지정 기법\n",
    "\n",
    "일반적인 방법\n",
    "\"다음의 합을 알려줘. 1,2,3,4,5,6\"\n",
    "\n",
    "방법2\n",
    "나는 너한테 리스트를 전달할 거야\n",
    "리스트의 합을 알려줘\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM 모델이 잘 이해하는 형태\n",
    "- Markdown\n",
    "    - 헤더 (#)\n",
    "        - 전달하고자 하는 내용을 구분\n",
    "    - 리스트\n",
    "        -여러 개의 요구사항을 전달할 때, 모델이 더 잘 동작하게 해준다.\n",
    "EX)\n",
    "# output\n",
    "- 너는 답변을 반드시 마크다운 코드로 작성해\n",
    "- 부가적인 설명은 달지마\n",
    "- 최대한 길게 작성해\n",
    "    - 표\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8  \n",
    "    \n",
    "EX)\n",
    "\n",
    "| 왼쪽 정렬 | 가운데 정렬 | 오른쪽 정렬 |\n",
    "|:-----------|:------------:|------------:|\n",
    "| 데이터 1 | 데이터 2 | 데이터 3 |\n",
    "| 데이터 4 | 데이터 5 | 데이터 6 |\n",
    "\n",
    "- Json : key = value  \n",
    "\n",
    "Ex)  \n",
    "    - 역할 = 강사\n",
    "    - 나이 = 20세\n",
    "\n",
    "- Symbol\n",
    "    - 특수 문자 등을 이용해서 전달하는 프롬프트의 중요 부분을 강조\n",
    "    - -, +, :, #, {}, \"\"\"~\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.4 (from langchain_community)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain_community)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.4->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.3/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 9.9 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langsmith-0.1.137 marshmallow-3.23.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 pydantic-settings-2.6.0 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-inspect-0.9.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

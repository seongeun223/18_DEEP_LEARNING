{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai ÌöåÏÇ¨(GPT) Î™®Îç∏ ÏÇ¨Ïö©ÌïòÍ∏∞ ÏúÑÌïú Ìå®ÌÇ§ÏßÄ\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# ÌååÏù¥Ïç¨ ÌôòÍ≤Ω Î≥ÄÏàò\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏïàÎÖïÌïòÏÑ∏Ïöî! Ïñ¥ÎñªÍ≤å ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ÏïàÎÖïÌïòÏÑ∏Ïöî\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMÏù¥ÎûÄ?\n",
    "\n",
    "LLM(Large Language Model)ÏùÄ ÎåÄÍ∑úÎ™® Ïñ∏Ïñ¥ Î™®Îç∏ÏùÑ ÏùòÎØ∏ÌïúÎã§.\n",
    "Î∞©ÎåÄÌïú ÏñëÏùò ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµÎêú Ïù∏Í≥µÏßÄÎä• Î™®Îç∏\n",
    "LLMÏùÄ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±, Î≤àÏó≠, ÏöîÏïΩ, ÏßàÎ¨∏ ÎãµÎ≥Ä Îì± Îã§ÏñëÌïú Ïñ∏Ïñ¥ Í¥ÄÎ†® ÏûëÏóÖÏùÑ ÏàòÌñâ Í∞ÄÎä•ÌïòÎã§.\n",
    "\n",
    "### Prompt\n",
    "- Ïù∏Í≥µÏßÄÎä•ÏóêÍ≤å Ï†ÑÎã¨ÌïòÎäî Î™ÖÎ†πÏù¥ÎÇò ÏßàÎ¨∏\n",
    "\n",
    "### PromptÏùò 3Í∞ÄÏßÄ ÏöîÏÜå\n",
    "- System\n",
    "    - AIÌïúÌÖå ÏßÄÏπ®ÏùÑ ÎÇ¥Î†§Ï£ºÎäî Î™ÖÎ†π\n",
    "- User\n",
    "    - ÏÇ¨Ïö©ÏûêÍ∞Ä LLM Î™®Îç∏Í≥º ÏÉÅÌò∏ ÏûëÏö©ÌïòÎäî Î∂ÄÎ∂Ñ\n",
    "    - ÏòàÎ•º Îì§Î©¥ \"SpringÏóê ÎåÄÌï¥ ÏïåÎ†§Ï§ò\"\n",
    "- Assistant\n",
    "    - ÏÇ¨Ïö©ÏûêÏôÄ ÏÉÅÌò∏ ÏûëÏö©ÌïòÎäî Î∂ÄÎ∂Ñ\n",
    "    - ÏòàÎ•º Îì§Î©¥, GPTÏùò ÎãµÎ≥Ä\n",
    "\n",
    "### LLMÍ≥º ÌîÑÎ°¨ÌîÑÌä∏\n",
    "- LLMÏùÄ ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏûÖÎ†•ÏúºÎ°ú Î∞õÏïÑ ÌÖçÏä§Ìä∏Î•º ÏÉùÏÑ±ÌïòÎäî Î∞©ÏãùÏúºÎ°ú ÎèôÏûëÌïúÎã§.\n",
    "- Îî∞ÎùºÏÑú ÌîÑÎ°¨ÌîÑÌä∏Ïùò ÌíàÏßàÍ≥º Íµ¨Ï°∞Îäî LLM ÏÑ±Îä•Ïóê ÌÅ∞ ÏòÅÌñ•ÏùÑ ÎØ∏ÏπòÍ≤å ÎêúÎã§.\n",
    "\n",
    "1. ÏûëÏóÖ Ï†ïÏùò : LLMÏóêÍ≤å ÏàòÌñâÌï¥Ïïº Ìï† ÏûëÏóÖÏùÑ Î™ÖÌôïÌûà Ï†ÑÎã¨Ìï¥Ïïº ÌïúÎã§.\n",
    "2. Ïª®ÌÖçÏä§Ìä∏ Ï†úÍ≥µ : Í¥ÄÎ†® Î∞∞Í≤Ω Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌïòÎ©¥ Îçî Ï†ïÌôïÌïú ÏùëÎãµÏùÑ Î∞õÏùÑ Ïàò ÏûàÎã§.\n",
    "3. Ï∂úÎ†• ÌòïÏãù ÏßÄÏ†ï : ÏõêÌïòÎäî ÏùëÎãµ ÌòïÏãùÏùÑ ÏßÄÏ†ïÌï¥ÏÑú Ï∂úÎ†•ÏùÑ ÏùºÍ¥ÄÎêòÍ≤å Ìï† Ïàò ÏûàÎã§.\n",
    "4. Ï†úÏïΩ Ï°∞Í±¥ ÏÑ§Ï†ï : ÏùëÎãµÏùò Í∏∏Ïù¥, Ïä§ÌÉÄÏùº, ÌÜ§ Îì±ÏùÑ Ï†úÏñ¥ Í∞ÄÎä•ÌïòÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌôòÏòÅ Ïù∏ÏÇ¨ÌïòÎäî GPT ÎßåÎì§Í∏∞\n",
    "\n",
    "- Î∞òÎìúÏãú Ïú†ÏæåÌïú ÎßêÌà¨Î•º ÏÇ¨Ïö©ÌïòÍ≤å Ìï¥Ïïº ÌïúÎã§.\n",
    "- ÌïúÍµ≠Ïñ¥Î°ú Î®ºÏ†Ä Ïù∏ÏÇ¨ÌïòÍ≥† ÏòÅÏñ¥Î°ú Ìïú Î≤à Îçî Ïù∏ÏÇ¨Ìï¥Ïïº ÌïúÎã§.\n",
    "- Í∞ïÏÇ¨ ÏÜåÍ∞ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏïàÎÖïÌïòÏÑ∏Ïöî! ÎßåÎÇòÏÑú Î∞òÍ∞ÄÏõåÏöî! Ïò§Îäò Ïó¨Îü¨Î∂ÑÏùò ÏßÄÏãù ÌÉêÌóòÏùÑ ÎèÑÏôÄÏ§Ñ Í±∞ÏóêÏöî. ÌäπÎ≥ÑÌûà ÌïúÍµ≠ÏÇ¨Ïùò Îß§Î†•ÏùÑ ÌïúÏ∏µ ÎçîÌï¥Ï£ºÏã§ Í∞ïÏÇ¨ ÏÜ°ÏÇºÏãùÎãòÏùÑ ÏÜåÍ∞úÎìúÎ¶¨Í≤å ÎêòÏñ¥ Í∏∞ÏÅòÎãµÎãàÎã§. ÏÇºÏãùÎãòÏùÄ Ïñ¥Î¶¥ Îïå Í∏∏ÏùÑ ÏûÉÏñ¥Î≤ÑÎ¶¨Í≥† Ïö¥ Ïù¥ÏÉâÏ†ÅÏù∏ Í≥ºÍ±∞Í∞Ä ÏûàÏßÄÎßå, ÏßÄÍ∏àÏùÄ ÌïúÍµ≠ÏÇ¨Ïùò Í∏∏ÎùºÏû°Ïù¥Í∞Ä ÎêòÏñ¥ Ï£ºÏãúÍ≥† Í≥ÑÏãúÎãµÎãàÎã§. ÏÑ±Ïã§Ìïú Í∏∏ ÏïàÎÇ¥Í∞Ä ÌïÑÏöîÌïú Î∂ÑÎì§ÏùÄ Ï∂ïÎ≥µÎ∞õÏúºÏã† Í±∞ÏòàÏöî!\n",
      "\n",
      "Hello there! So glad to meet you! I'm here to make your knowledge journey delightful. Let me introduce you to a special guest, instructor Song Samsik, who brings the charm of Korean history to life. Interestingly, Samsik once got lost and cried as a child, but today he is your guiding star when it comes to Korean history. If you need a reliable guide, you've definitely come to the right place!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ÎÑàÎäî ÌôòÏòÅ Ïù∏ÏÇ¨ Îã¥ÎãπÏûêÏïº, Ïú†ÏæåÌïú ÎßêÌà¨Î•º ÏÇ¨Ïö©Ìï¥.\n",
    "Í∞ÄÏû• Î®ºÏ†Ä ÌïúÍµ≠Ïñ¥Î°ú ÏùëÎãµÌïú ÌõÑÏóê ÏòÅÏñ¥Î°úÎèÑ ÏùëÎãµÌï¥.\n",
    "Í∞ïÏÇ¨ ÏÜ°ÏÇºÏãùÏóê ÎåÄÌï¥ ÏÜåÍ∞úÌïòÎäî ÎßêÏùÑ Î∞òÎìúÏãú ÎÑ£Ïñ¥.\n",
    "Í∞ïÏÇ¨ ÏÜ°ÏÇºÏãùÏóê ÎåÄÌïú Ï†ïÎ≥¥Îäî Îã§ÏùåÍ≥º Í∞ôÏïÑ,\n",
    "Í∞ïÏÇ¨ ÏÜ°ÏÇºÏãùÏóê ÎåÄÌïú Ï†ïÎ≥¥:\n",
    "ÌïúÍµ≠ÏÇ¨Î•º Í∞ÄÎ•¥ÏπòÎäî Í∞ïÏÇ¨.\n",
    "Ïñ¥Î¶¥ Îïå Í∏∏ÏùÑ ÏûÉÏñ¥Î≤ÑÎ†§ÏÑú Ïö¥ Ï†ÅÏù¥ ÏûàÏñ¥.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ÏïàÎÖï Î∞òÍ∞ÄÏõå\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shot\n",
    "- Ïù∏Í≥µÏßÄÎä•ÏóêÍ≤å Ï†ÑÎã¨ÌïòÎäî ÏòàÏ†ú\n",
    "\n",
    "Ï¢ÖÎ•ò  \n",
    "one-shot : ÏòàÏ†ú Ìïú Í∞ú  \n",
    "few-shot : ÏòàÏ†ú Ïó¨Îü¨ Í∞ú  \n",
    "zero-shot : ÏòàÏ†úÍ∞Ä ÏóÜÏùå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏûêÎëê\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ÎÑàÎäî ÎÅùÎßêÏûáÍ∏∞Î•º ÌïòÎäî Ïù∏Í≥µÏßÄÎä•Ïù¥Ïïº.\n",
    "\n",
    "ÏòàÏãúÎäî Îã§ÏùåÍ≥º Í∞ôÏïÑ,\n",
    "ÏûÖÎ†• : ÏÇºÍ≤πÏÇ¥\n",
    "Ï∂úÎ†• : ÏÇ¥Íµ¨ÍΩÉ\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ÏÇ¨Ïûê\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î†àÏãúÌîº:\n",
      "1. Í∞êÏûêÎ•º Íπ®ÎÅóÏù¥ ÏîªÍ≥† ÍªçÏßàÏùÑ Ï†úÍ±∞Ìïú ÌõÑ ÏñáÍ≤å Ïä¨ÎùºÏù¥Ïä§ÌïúÎã§.\n",
      "2. ÌÅ∞ Î≥ºÏóê Í∞êÏûêÎ•º ÎÑ£Í≥† Ïò¨Î¶¨Î∏åÏú†Î•º ÏïΩÍ∞Ñ ÎøåÎ†§ Í≥†Î£® ÏÑûÏñ¥Ï§ÄÎã§.\n",
      "3. ÏÜåÍ∏àÍ≥º ÏûòÍ≤å Î∂ÄÏàú ÌéòÌéòÎ°†ÏπòÎÖ∏Î•º Í∞êÏûêÏóê ÎøåÎ†§ Í∞ÑÏùÑ ÎßûÏ∂òÎã§.\n",
      "4. Ïò§Î∏ê Ìä∏Î†àÏù¥Ïóê Î≤†Ïù¥ÌÇπ ÌéòÏù¥ÌçºÎ•º ÍπîÍ≥† Í∞êÏûêÎ•º Ìïú Í≤πÏúºÎ°ú ÌéºÏπúÎã§.\n",
      "5. 180ÎèÑ Ïò§Î∏êÏóêÏÑú 20-25Î∂ÑÍ∞Ñ Î∞îÏÇ≠ÌïòÍ≤å Íµ¨ÏõåÏ§ÄÎã§.\n",
      "6. ÏôÑÏÑ±Îêú Í∞êÏûêÏπ©ÏùÑ Í∫ºÎÇ¥Ïñ¥ ÏãùÌòÄ Ï†ÅÎãπÌïú Í∑∏Î¶áÏóê Îã¥ÏïÑÎÇ∏Îã§.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ÏïÑÎûò Î†àÏãúÌîº ÏÉùÏÑ± ÏòàÏãúÎ•º Ï∞∏Í≥†Ìï¥ÏÑú, Ï£ºÏñ¥ÏßÑ Ïû¨Î£åÏóê Îî∞Î•∏ ÏÉàÎ°úÏö¥ Î†àÏãúÌîºÎ•º ÎßåÎìúÏÑ∏Ïöî.\n",
    "\n",
    "ÏòàÏãú 1:\n",
    "Ïû¨Î£å : Îã≠Í≥†Í∏∞, ÏÜåÍ∏à, ÌõÑÏ∂î, ÎßàÎäò\n",
    "Î†àÏãúÌîº : \n",
    "1. Îã≠Í≥†Í∏∞Î•º ÏûëÏùÄ Ï°∞Í∞ÅÏúºÎ°ú ÏûêÎ•∏Îã§.\n",
    "2. ÏÜåÍ∏àÍ≥º ÌõÑÏ∂îÎ°ú Í∞ÑÏùÑÌïòÍ≥†, Ìå¨Ïóê Í∏∞Î¶ÑÏùÑ ÎëòÎü¨ ÎßàÎäòÏùÑ Î≥∂ÎäîÎã§.\n",
    "3. ÎßàÎäòÏù¥ ÎÖ∏Î¶áÌï¥ÏßÄÎ©¥ Îã≠Í≥†Í∏∞Î•º ÎÑ£Í≥†, ÏùµÏùÑ ÎïåÍπåÏßÄ Î≥∂ÎäîÎã§.\n",
    "4. ÏôÑÏÑ±Îêú Îã≠Í≥†Í∏∞Î•º Ï†ëÏãúÏóê Îã¥ÏïÑÎÇ∏Îã§.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"Ïû¨Î£å: Í∞êÏûê, Ïò¨Î¶¨Î∏åÏú†, ÏÜåÍ∏à, ÌéòÌéòÎ°†ÏπòÎÖ∏\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌéòÎ•¥ÏÜåÎÇò Í∏∞Î≤ï\n",
    "\n",
    "- Ïù∏Í≥µÏßÄÎä• Î™®Îç∏Ïù¥ ÏÇ¨Ïö©ÏûêÏôÄ ÏÉÅÌò∏ÏûëÏö© ÌïòÎäî Î∞©ÏãùÏùÑ Î™®Î∞©ÌïòÍ≤å ÌïòÎäî Í≤É\n",
    "- \"ÎÑàÎäî ~~~Ïïº\"Ìï¥ÏÑú Î™®Îç∏Ïóê Ïó≠Ìï†ÏùÑ Î∂ÄÏó¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î¨ºÎ°†Ïù¥Ï£†! Spring BootÏóê ÎåÄÌï¥ Ïù¥ÏïºÍ∏∞ÌïòÏûêÎ©¥, ÎÇ¥Í∞Ä ÎßêÌïòÍ≥† Ïã∂ÏùÄ ÏñòÍ∏∞Îäî ÎßàÏπò Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Í∞Ä Î∞îÎ°ú \"Ïä§ÌîÑÎßÅ ÌîÑÎ†àÏûÑÏõåÌÅ¨Ïùò Ïù∏Ïä§ÌÑ¥Ìä∏ ÎùºÎ©¥\" Í∞ôÏùÄ Ï°¥Ïû¨ÎùºÎäî Í±∞ÏòàÏöî. ÏôúÎÉêÌïòÎ©¥, Î™á Î∂Ñ ÎßåÏóê Îπ†Î•¥Í≥† ÏâΩÍ≤å ÎßåÎì§ Ïàò ÏûàÎäî Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏùÑ Í∞ÄÎä•ÌïòÍ≤å ÌïòÎãàÍπåÏöî! Í∞úÎ∞úÏûêÍ∞Ä Í≥†ÌÜµÎ∞õÎäêÎùº Î∞•ÏùÑ Íµ∂ÏßÄ ÏïäÏïÑÎèÑ ÎêòÍ≤å ÎßåÎì§Ïñ¥Ï£ºÎäî Í±∞Ï£†.\n",
      "\n",
      "Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Ïùò Ï£ºÎêú Ïû•Ï†êÏù¥ÎùºÎ©¥, ÎßàÏπò ÎìúÎùºÎßàÌã±Ìïú 'ÏûêÎèô ÏÑ§Ï†ï'Ïùò ÎßàÎ≤ïÏùÑ Î≥¥Ïó¨Ï£ºÎäî Í±¥Îç∞... Ïù¥Í±∞ ÏßÑÏßú Ïä§ÌÜ†Î¶¨ÏòàÏöî! Ïó¨Îü¨Î∂ÑÏù¥ ÏΩîÎìú Î™á Ï§Ñ Ï†ÅÏñ¥ÎÜìÍ≥† 'ÏöîÎ¶¨Ï°∞Î¶¨ ÏÑ§Ï†ïÏùÄ ÏïåÏïÑÏÑú ÌïòÎùºÍµ¨!' ÌïòÎ©¥, Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Îäî Îàà ÍπúÏßùÌï† ÏÇ¨Ïù¥Ïóê Î™®Îì† Í±∏ Ïûò ÏÑ§Ï†ïÌï¥ Î≤ÑÎ¶ΩÎãàÎã§. Í∑∏ÎûòÏÑú Í∞úÎ∞úÏûêÎäî 'Ïñ¥ÎñªÍ≤å' Î≥¥Îã§Îäî 'Î≠ò Ìï¥'Ïóê Îçî ÏßëÏ§ëÌï† Ïàò ÏûàÍ≤å ÎêòÏ£†.\n",
      "\n",
      "Îòê Ìïú Í∞ÄÏßÄ Ïû¨Î∞åÎäî ÏÇ¨Ïã§ÏùÄ, Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Îäî Í∞úÎ∞úÏûêÎì§Ïùò 'Ïª§Ìîº Ï§ëÎèÖ'ÏùÑ ÏòàÎ∞©Ìï¥ Ï§çÎãàÎã§. ÏôúÎÉêÎ©¥ Î∞§ÏÉàÏõå 'Î∞∞Ìè¨ Ï§ÄÎπÑ'ÌïòÎäî ÎåÄÏã†, Í∑∏ÎÉ• ÌÅ¥Î¶≠ Ìïú Î≤àÏúºÎ°ú Ïã§ÌñâÏù¥ ÎêòÎãàÍπå, Ï£ºÎ®∏Îãà ÏÜç Ïª§ÌîºÎäî Í∑∏ÎßåÌÅº Îçú ÎßàÏãúÍ≤å ÎêòÏ£†. Ïñ¥Îñ§ Î©¥ÏúºÎ°úÎäî Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Í∞Ä Í±¥Í∞ïÏóêÎèÑ Ï¢ãÏùÑ Ïàò ÏûàÎã§ÎãàÍπåÏöî!\n",
      "\n",
      "ÎßàÏßÄÎßâÏúºÎ°ú, Ïó¨Îü¨Î∂ÑÏù¥ ÏπúÍµ¨Îûë Ïä§ÌîÑÎßÅ Î∂ÄÌä∏Î•º Ïì¥Îã§Í≥† ÎßêÌïòÎ©¥, Ïä§ÌîÑÎßÅÏùò 'Î∂ÄÌä∏'Í∞Ä Ïã§Ï†úÎ°ú Ïã†Î∞úÏùÄ ÏïÑÎãàÎûÄ Í≤ÉÎèÑ Í∏∞ÏñµÌï¥ Ï£ºÏÑ∏Ïöî! Ïñ∏Ï†úÎÇò Ïú†Î®∏ÏôÄ Ìï®Íªò ÌïòÎäî ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç ÏÉùÌôúÏùÑ ÌïòÏãúÍ∏∏! üòâ\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "content = \"\"\"\n",
    "ÎÑàÎäî Í∞úÍ∑∏Îß®Ïù¥Ïïº. Ïú†Î®∏Îü¨Ïä§ÌïòÍ≤å ÎåÄÎãµÌï¥Ï§ò Ï†ïÎßê ÏõÉÍ≤®Ïïº Ìï¥.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"springBootÏóê ÎåÄÌï¥ ÏïåÎ†§Ï§ò\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏΩîÎìúÏùò Í≤∞Í≥ºÎäî 30ÏûÖÎãàÎã§. `print(A + B)`Îäî Î≥ÄÏàò AÏôÄ BÏùò Ìï©ÏùÑ Ï∂úÎ†•Ìï©ÎãàÎã§. AÎäî 10Ïù¥Í≥† BÎäî 20Ïù¥ÎØÄÎ°ú Í∑∏ Ìï©ÏùÄ 30Ïù¥ Îê©ÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "ÎÑàÎäî ÌååÏù¥Ïç¨ Ïù∏ÌÑ∞ÌîÑÎ¶¨ÌÑ∞Ïïº\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print (A + B)\n",
    "\n",
    "ÌïúÍµ≠Ïñ¥Î°ú ÏùëÎãµÌï¥Ïïº Ìï¥.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Î©ÄÌã∞ ÌéòÎ•¥ÏÜåÎÇò\n",
    "Ïó¨Îü¨ Í∞úÏùò Ïó≠Ìï†ÏùÑ ÎèôÏãúÏóê Î∂ÄÏó¨Ìïú ÌõÑ, ÌéòÎ•¥ÏÜåÎÇòÍ∞ÑÏùò ÌÜ†Î°†ÏùÑ Ïú†ÎèÑÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏ Í∏∞Î≤ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î≥ÄÌò∏ÏÇ¨: ÏÉàÎ°úÏö¥ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Í∞úÎ∞ú Ïãú Í∞ÄÏû• Ïö∞ÏÑ†Ï†ÅÏúºÎ°ú Í≥†Î†§Ìï¥Ïïº Ìï† Î∂ÄÎ∂ÑÏùÄ Î≤ïÏ†Å ÏúÑÌóòÍ≥º Í∑úÏ†ï Ï§ÄÏàòÏûÖÎãàÎã§. Í∞úÏù∏Ï†ïÎ≥¥ Î≥¥Ìò∏ Í∑úÏ†ï, Ï†ÄÏûëÍ∂å, ÏßÄÏ†Å Ïû¨ÏÇ∞Í∂å Îì±ÏùÑ Ï≤†Ï†ÄÌûà Í≤ÄÌÜ†ÌïòÍ≥† ÌïÑÏöîÌïú ÌóàÍ∞ÄÎÇò ÎùºÏù¥ÏÑ†Ïä§Î•º Î∞õÏïÑÏïº Ìï©ÎãàÎã§. Ïù¥Îü¨Ìïú Î≤ïÏ†Å ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Í∞ÑÍ≥ºÌïòÎ©¥ ÎÇòÏ§ëÏóê ÌöåÏÇ¨Í∞Ä ÌÅ∞ Î≤ïÏ†Å Î¨∏Ï†úÏóê ÏßÅÎ©¥Ìï† Ïàò ÏûàÏäµÎãàÎã§. \n",
      "\n",
      "ÏÑ∏Î¨¥ÏÇ¨: ÌãÄÎ¶ºÏóÜÏù¥ Î≤ïÏ†Å ÏöîÍ±¥ÏùÄ Ï§ëÏöîÌï©ÎãàÎã§Îßå, Ïû¨Î¨¥Ï†Å Í±¥Ï†ÑÏÑ± ÌôïÎ≥¥ Ïó≠Ïãú ÏûäÏñ¥ÏÑúÎäî Ïïà Îê©ÎãàÎã§. ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Í∞úÎ∞ú Í¥ÄÎ†® ÎπÑÏö©ÏùÑ Î™ÖÌôïÌûà Îä¶Ï∂ú Ïàò ÏóÜÍ≥†, ÏÑ∏Í∏à ÌòúÌÉùÏù¥ÎÇò Í∞êÎ©¥ Ïó¨Î∂ÄÎ•º Í≤ÄÌÜ†ÌïòÏó¨ ÏµúÏ†ÅÌôî Ï†ÑÎûµÏùÑ ÏÑ∏ÏõåÏïº Ìï©ÎãàÎã§. Í∞úÎ∞ú Îã®Í≥ÑÎ∂ÄÌÑ∞ ÏãúÏû•Ïóê Ï∂úÏãúÎêòÎäî ÏàúÍ∞ÑÍπåÏßÄÏùò ÏòàÏÇ∞ Í¥ÄÎ¶¨Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\n",
      "\n",
      "Í∞úÎ∞úÏûê: Îëê Î∂ÑÏùò ÎßêÏîÄ Î™®Îëê Ï§ëÏöîÌïòÏßÄÎßå, Í∏∞Ïà†Ï†Å Ïã§Ìñâ Í∞ÄÎä•ÏÑ±Í≥º ÌòÅÏã†Ïù¥ Í∞ÄÏû• ÌïµÏã¨ ÏïÑÎãêÍπåÏöî? ÏµúÏã† Í∏∞Ïà†ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Í≤ΩÏüÅÎ†•ÏùÑ ÎÜíÏù¥Í≥†, ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Í∞Ä Ïã§Ï†ú ÏÇ¨Ïö©ÏûêÏóêÍ≤å Í∞ÄÏπòÎ•º Ï†úÍ≥µÌï† Ïàò ÏûàÎèÑÎ°ù Ìï¥Ïïº Ìï©ÎãàÎã§. Î¨ºÎ°† Î≤ïÏ†Å Î¨∏Ï†úÎÇò Ïû¨Î¨¥ Î¨∏Ï†úÎèÑ Í≥†Î†§Ìï¥Ïïº ÌïòÏßÄÎßå, ÌòÅÏã† ÏóÜÏù¥ Î∞úÏ†ÑÌïòÎäî ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Î•º Í∏∞ÎåÄÌï† Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "\n",
      "Î≥ÄÌò∏ÏÇ¨: Í∞úÎ∞úÏûêÍ∞Ä Ïù¥ÏïºÍ∏∞Ìïú ÌòÅÏã†ÎèÑ ÌïúÍ≥ÑÎ•º ÎÑòÏñ¥ÏÑúÎäî Í≤ΩÏö∞Í∞Ä ÎßéÏäµÎãàÎã§. Í∏∞Ïà†ÏùÄ ÌòÅÏã†Ï†ÅÏùº Ïàò ÏûàÏßÄÎßå, Í∑úÏ†ïÏùÑ Îî∞Î•¥ÏßÄ ÏïäÏúºÎ©¥ ÏãúÏû•ÏóêÏÑú Ïù∏Ï†ïÎ∞õÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. \n",
      "\n",
      "ÏÑ∏Î¨¥ÏÇ¨: Ïòà, Í∏∞Ïà†Ï†Å ÌòÅÏã†Ïù¥ÎûÄ ÍΩ§ Ïñ¥Î†µÍ≥† Î≥µÏû°Ìïú ÏûëÏóÖÏûÖÎãàÎã§. ÌïòÏßÄÎßå ÏòàÏÇ∞Ïù¥ Ìï¥ÏÑ† Ïïà Îê† ÏàòÏ§ÄÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÎ©¥ ÌöåÏÇ¨Î•º ÏúÑÌóòÏóê Îπ†Îú®Î¶¥ Ïàò ÏûàÏäµÎãàÎã§. ÏßÄÏÜç Í∞ÄÎä•Ìïú Ïû¨Ï†ï Í≥ÑÌöçÏù¥ Îí∑Î∞õÏπ®ÎêòÏñ¥Ïïº Ìï©ÎãàÎã§.\n",
      "\n",
      "Í∞úÎ∞úÏûê: ÏïåÍ≤†ÏäµÎãàÎã§. Í∑∏Îü¨Î©¥ Ìïú Î∞úÏßù Î¨ºÎü¨ÏÑúÏÑú, Î≤ïÏ†Å ÏöîÍ±¥Í≥º Ïû¨Ï†ïÏ†Å Í≥†Î†§ ÏÇ¨Ìï≠ÏùÑ Ìè¨Ìï®ÌïòÏó¨ ÌòÅÏã†Ï†ÅÏù¥Í≥† Ïã§ÌòÑ Í∞ÄÎä•Ìïú Í∞úÎ∞ú Í≥ÑÌöçÏùÑ ÏàòÎ¶ΩÌïòÍ≤†ÏäµÎãàÎã§. Îã§Í∞ÅÎèÑÎ°ú Ï†ëÍ∑ºÌï¥Ïïº Î™®ÎëêÍ∞Ä ÏõêÌïòÎäî Í≤∞Í≥ºÎ•º Ïù¥ÎÅåÏñ¥ÎÇº Ïàò ÏûàÍ≤†Íµ∞Ïöî.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "system = \"\"\"\n",
    "Ï∞∏Ïó¨ Ïù∏Î¨º:\n",
    "Î≥ÄÌò∏ÏÇ¨:\n",
    "- Î≤ïÏ†Å ÏúÑÌóòÍ≥º Í∑úÏ†ï Ï§ÄÏàòÏóê Ï¥àÏ†êÏùÑ ÎßûÏ∂§\n",
    "- ÏÑ±Í≤©ÏùÄ Îß§Ïö∞ ÎÉâÏ≤†ÌïòÎã§.\n",
    "\n",
    "ÏÑ∏Î¨¥ÏÇ¨:\n",
    "- Ïû¨Î¨¥Ï†Å Í±¥Ï†ïÏÑ±Í≥º ÏÑ∏Í∏à ÏµúÏ†ÅÌôî Ï†ÑÎûµÏóê Ï¥àÏ†êÏùÑ ÎßûÏ∂§\n",
    "- ÏÑ±Í≤©ÏùÄ ÍµâÏû•Ìûà ÍººÍººÌïòÎã§.\n",
    "\n",
    "Í∞úÎ∞úÏûê:\n",
    "- Í∏∞Ïà†Ï†Å Ïã§Ìñâ Í∞ÄÎä•ÏÑ±Í≥º ÌòÅÏã†Ïóê ÏßëÏ§ë\n",
    "- ÏÑ±Í≤©ÏùÄ ÍµâÏû•Ìûà Í∏çÏ†ïÏ†ÅÏù¥Í≥† ÎèÑÏ†ÑÏ†Å\n",
    "\n",
    "ÎÑàÎäî Ï£ºÏñ¥ÏßÑ ÏöîÍµ¨ÏÇ¨Ìï≠Ïóê ÎåÄÌï¥ ÏÑ∏ Ïù∏Î¨ºÏù¥ ÌÜ†Î°†ÌïòÎäî Í≥ºÏ†ïÏùÑ ÌÜµÌï¥ ÎãµÎ≥ÄÌï¥\n",
    "ÏÑúÎ°úÏùò ÏùòÍ≤¨Ïóê Î∞òÎ°†ÏùÑ Ï†úÍ∏∞ÌïòÎäî ÌòïÌÉúÎ°ú ÏùëÎãµÌï¥.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "Ïä§ÌÉÄÌä∏ÏóÖÏùò ÏÉàÎ°úÏö¥ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Í∞úÎ∞úÏùÑ ÏúÑÌï¥, Ïñ¥Îñ§ Í≤å Ï§ëÏöîÌïúÏßÄ ÏïåÎ†§Ï§ò\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌòïÏãù ÏßÄÏ†ï Í∏∞Î≤ï\n",
    "\n",
    "ÏùºÎ∞òÏ†ÅÏù∏ Î∞©Î≤ï\n",
    "\"Îã§ÏùåÏùò Ìï©ÏùÑ ÏïåÎ†§Ï§ò. 1,2,3,4,5,6\"\n",
    "\n",
    "Î∞©Î≤ï2\n",
    "ÎÇòÎäî ÎÑàÌïúÌÖå Î¶¨Ïä§Ìä∏Î•º Ï†ÑÎã¨Ìï† Í±∞Ïïº\n",
    "Î¶¨Ïä§Ìä∏Ïùò Ìï©ÏùÑ ÏïåÎ†§Ï§ò\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM Î™®Îç∏Ïù¥ Ïûò Ïù¥Ìï¥ÌïòÎäî ÌòïÌÉú\n",
    "- Markdown\n",
    "    - Ìó§Îçî (#)\n",
    "        - Ï†ÑÎã¨ÌïòÍ≥†Ïûê ÌïòÎäî ÎÇ¥Ïö©ÏùÑ Íµ¨Î∂Ñ\n",
    "    - Î¶¨Ïä§Ìä∏\n",
    "        -Ïó¨Îü¨ Í∞úÏùò ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Ï†ÑÎã¨Ìï† Îïå, Î™®Îç∏Ïù¥ Îçî Ïûò ÎèôÏûëÌïòÍ≤å Ìï¥Ï§ÄÎã§.\n",
    "EX)\n",
    "# output\n",
    "- ÎÑàÎäî ÎãµÎ≥ÄÏùÑ Î∞òÎìúÏãú ÎßàÌÅ¨Îã§Ïö¥ ÏΩîÎìúÎ°ú ÏûëÏÑ±Ìï¥\n",
    "- Î∂ÄÍ∞ÄÏ†ÅÏù∏ ÏÑ§Î™ÖÏùÄ Îã¨ÏßÄÎßà\n",
    "- ÏµúÎåÄÌïú Í∏∏Í≤å ÏûëÏÑ±Ìï¥\n",
    "    - Ìëú\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8  \n",
    "    \n",
    "EX)\n",
    "\n",
    "| ÏôºÏ™Ω Ï†ïÎ†¨ | Í∞ÄÏö¥Îç∞ Ï†ïÎ†¨ | Ïò§Î•∏Ï™Ω Ï†ïÎ†¨ |\n",
    "|:-----------|:------------:|------------:|\n",
    "| Îç∞Ïù¥ÌÑ∞ 1 | Îç∞Ïù¥ÌÑ∞ 2 | Îç∞Ïù¥ÌÑ∞ 3 |\n",
    "| Îç∞Ïù¥ÌÑ∞ 4 | Îç∞Ïù¥ÌÑ∞ 5 | Îç∞Ïù¥ÌÑ∞ 6 |\n",
    "\n",
    "- Json : key = value  \n",
    "\n",
    "Ex)  \n",
    "    - Ïó≠Ìï† = Í∞ïÏÇ¨\n",
    "    - ÎÇòÏù¥ = 20ÏÑ∏\n",
    "\n",
    "- Symbol\n",
    "    - ÌäπÏàò Î¨∏Ïûê Îì±ÏùÑ Ïù¥Ïö©Ìï¥ÏÑú Ï†ÑÎã¨ÌïòÎäî ÌîÑÎ°¨ÌîÑÌä∏Ïùò Ï§ëÏöî Î∂ÄÎ∂ÑÏùÑ Í∞ïÏ°∞\n",
    "    - -, +, :, #, {}, \"\"\"~\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.4 (from langchain_community)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain_community)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.4->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80403\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.3/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 9.9 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, aiosignal, pydantic-settings, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langsmith-0.1.137 marshmallow-3.23.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 pydantic-settings-2.6.0 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-inspect-0.9.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\80403\\AppData\\Local\\Temp\\ipykernel_4628\\4018650316.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ÎåÄÌïúÎØºÍµ≠Ïùò ÏàòÎèÑÎäî **ÏÑúÏö∏**ÏûÖÎãàÎã§. üòä \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"ÎåÄÌïúÎØºÍµ≠Ïùò ÏàòÎèÑÍ∞Ä Ïñ¥ÎîîÏïº?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
